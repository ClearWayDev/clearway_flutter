import 'dart:async';
import 'dart:typed_data';
import 'package:camera/camera.dart';
import 'package:clearway/services/guidanceservice.dart';
import 'package:flutter/foundation.dart'; // for kIsWeb
import 'package:flutter_tts/flutter_tts.dart';
import 'package:google_generative_ai/google_generative_ai.dart';
import 'package:image/image.dart' as img;

class ImageDescriptionService {
  final FlutterTts _flutterTts = FlutterTts();
  final String _geminiApiKey = "AIzaSyDYSPxTvZQsjES1m-11lotUSXb2eJAK9Vs";

  bool _isLooping = false;
  bool _stopRequested = false;

  CameraController? _cameraController;

  Future<void> _initializeCamera() async {
    final cameras = await availableCameras();
    final rearCamera = cameras.firstWhere(
      (camera) => camera.lensDirection == CameraLensDirection.back,
    );
    _cameraController = CameraController(
      rearCamera,
      ResolutionPreset.medium,
      enableAudio: false,
    );
    await _cameraController!.initialize();
    print("üì∑ Camera initialized.");
  }

  Future<XFile?> autoCaptureImage() async {
    try {
      if (_cameraController == null ||
          !_cameraController!.value.isInitialized) {
        await _initializeCamera();
      }

      print("üì∏ Auto-capturing image...");
      return await _cameraController!.takePicture();
    } catch (e) {
      print("‚ùå Failed to auto-capture: $e");
      return null;
    }
  }

  Future<Uint8List> compressImage(XFile imageFile) async {
    print("üìâ Compressing image...");
    final bytes = await imageFile.readAsBytes();
    final original = img.decodeImage(bytes);

    if (original == null) {
      throw Exception("Failed to decode image");
    }

    final resized = img.copyResize(original, width: 512);
    final compressed = img.encodeJpg(resized, quality: 70);
    return Uint8List.fromList(compressed);
  }

  Future<String> describeImageOnly(Uint8List imageBytes) async {
    print("üß† Describing image only...");

    final model = GenerativeModel(
      model: 'gemini-1.5-flash',
      apiKey: _geminiApiKey,
      generationConfig: GenerationConfig(maxOutputTokens: 512),
    );

    try {
      final response = await model.generateContent([
        Content.multi([
          TextPart(
            "You are helping a blind person navigate their surroundings based on the image alone.\n\n"
            "- Can the person move forward safely?\n"
            "- Are there any objects or people in front?\n"
            "- Mention any obstacles or dangers clearly and briefly.",
          ),
          DataPart('image/jpeg', imageBytes),
        ]),
      ]);

      final result = response.text?.trim();
      print("ü§ñ Image-only response:\n$result");

      if (result == null || result.isEmpty) {
        return "Unable to describe the image.";
      }
      return result;
    } catch (e) {
      print("‚ùå Gemini (image only) failed: $e");
      return "Error describing the image: $e";
    }
  }

  Future<String> getFirstDirection(String guidanceText) async {
    print("üß≠ Summarizing first direction...");

    final model = GenerativeModel(
      model: 'gemini-1.5-flash',
      apiKey: _geminiApiKey,
      generationConfig: GenerationConfig(maxOutputTokens: 256),
    );

    try {
      final response = await model.generateContent([
        Content.text(
          "Here are walking directions: $guidanceText\n\n"
          "Please extract and return only the *first meaningful instruction* "
          "(e.g., 'Head east on Main St'). Do not repeat the full directions.",
        ),
      ]);

      final result = response.text?.trim();
      print("ü§ñ First direction response:\n$result");

      if (result == null || result.isEmpty) {
        return "Unable to extract first direction.";
      }
      return result;
    } catch (e) {
      print("‚ùå Gemini (first direction) failed: $e");
      return "Error extracting direction: $e";
    }
  }

  Future<void> speak(String text) async {
    await _flutterTts.setLanguage("en-US");
    await _flutterTts.setSpeechRate(0.5);
    await _flutterTts.setPitch(1.0);
    await _flutterTts.speak(text);
  }

  Future<void> stopSpeak() async {
    print("üõë Stopping speech...");
    try {
      await _flutterTts.stop();
    } catch (e) {
      print("‚ùå Error stopping speech: $e");
    }
  }

  Future<String?> captureDescribeSpeak() async {
    if (_isLooping) {
      _stopRequested = true;
      return null;
    }

    _isLooping = true;
    _stopRequested = false;
    String? lastDescription;

    while (!_stopRequested) {
      final photo = await autoCaptureImage();
      if (photo == null) break;

      final compressedBytes = await compressImage(photo);

      final imgDesc = await describeImageOnly(compressedBytes);
      final guidanceService = GuidanceService();
      final directionsRaw = await guidanceService.getGuidance("Galle fort");
      final firstDir = await getFirstDirection(directionsRaw);

      String guidance = await guidanceService.getGuidance("Galle fort");

      print("üß≠ Guidance received: $guidance");
      final combined = "$imgDesc. $firstDir";
      await speak(combined);
      lastDescription = combined;

      if (_stopRequested) break;

      print("‚è≥ Waiting 10 seconds...");
      for (int i = 0; i < 10; i++) {
        if (_stopRequested) break;
        await Future.delayed(Duration(seconds: 1));
      }
    }

    _isLooping = false;
    _stopRequested = false;
    await _cameraController?.dispose();
    _cameraController = null;

    print("‚úÖ Loop finished.");
    return lastDescription;
  }
}
